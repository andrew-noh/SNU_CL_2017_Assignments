{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 201)\n"
     ]
    }
   ],
   "source": [
    "# Import models\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "import numpy\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(5)\n",
    "# load pima indians dataset\n",
    "dataset = numpy.loadtxt(\"SimpleNetData.csv\", delimiter=\",\")\n",
    "\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 200) (8000,) (2000, 200) (2000,)\n"
     ]
    }
   ],
   "source": [
    "# Split train and test data\n",
    "split = 0.8\n",
    "train_range = int(dataset.shape[0] * split)\n",
    "data_range = int(dataset.shape[1]) - 1\n",
    "\n",
    "x_train = dataset[:train_range,0:data_range]\n",
    "y_train = dataset[:train_range,data_range]\n",
    "x_test = dataset[train_range:,0:data_range]\n",
    "y_test = dataset[train_range:,data_range]\n",
    "\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Net\n",
    "model = Sequential()\n",
    "model.add(Dense(350, input_dim=200, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(200, activation='tanh'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "#(Adam) All tanh: 82.70%, all relu: 84.40%, relu&tanh: 83.70%, tanh&relu: 82.75%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "8000/8000 [==============================] - 1s 110us/step - loss: 1.0359 - acc: 0.6485\n",
      "Epoch 2/150\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 0.6953 - acc: 0.7571\n",
      "Epoch 3/150\n",
      "8000/8000 [==============================] - 0s 47us/step - loss: 0.5971 - acc: 0.7864\n",
      "Epoch 4/150\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 0.5363 - acc: 0.8055\n",
      "Epoch 5/150\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.4833 - acc: 0.8273\n",
      "Epoch 6/150\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 0.4517 - acc: 0.8391\n",
      "Epoch 7/150\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.4201 - acc: 0.8514\n",
      "Epoch 8/150\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 0.4010 - acc: 0.8532\n",
      "Epoch 9/150\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 0.3786 - acc: 0.8555\n",
      "Epoch 10/150\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.3654 - acc: 0.8654\n",
      "Epoch 11/150\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 0.3430 - acc: 0.8757\n",
      "Epoch 12/150\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 0.3275 - acc: 0.8774\n",
      "Epoch 13/150\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 0.3163 - acc: 0.8835\n",
      "Epoch 14/150\n",
      "8000/8000 [==============================] - 0s 47us/step - loss: 0.3028 - acc: 0.8902\n",
      "Epoch 15/150\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 0.2979 - acc: 0.8908\n",
      "Epoch 16/150\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.2840 - acc: 0.8939\n",
      "Epoch 17/150\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 0.2762 - acc: 0.8926\n",
      "Epoch 18/150\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 0.2657 - acc: 0.8992\n",
      "Epoch 19/150\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.2567 - acc: 0.9025\n",
      "Epoch 20/150\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.2482 - acc: 0.9082\n",
      "Epoch 21/150\n",
      "8000/8000 [==============================] - 0s 47us/step - loss: 0.2457 - acc: 0.9116\n",
      "Epoch 22/150\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 0.2355 - acc: 0.9135\n",
      "Epoch 23/150\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 0.2268 - acc: 0.9171\n",
      "Epoch 24/150\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.2341 - acc: 0.9124\n",
      "Epoch 25/150\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.2162 - acc: 0.9220\n",
      "Epoch 26/150\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.2152 - acc: 0.9211\n",
      "Epoch 27/150\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 0.2030 - acc: 0.9225\n",
      "Epoch 28/150\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.2020 - acc: 0.9279\n",
      "Epoch 29/150\n",
      "8000/8000 [==============================] - 0s 47us/step - loss: 0.1972 - acc: 0.9260\n",
      "Epoch 30/150\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 0.1893 - acc: 0.9271\n",
      "Epoch 31/150\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 0.1828 - acc: 0.9335\n",
      "Epoch 32/150\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.1788 - acc: 0.9328\n",
      "Epoch 33/150\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.1740 - acc: 0.9391\n",
      "Epoch 34/150\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 0.1752 - acc: 0.9324\n",
      "Epoch 35/150\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 0.1682 - acc: 0.9341\n",
      "Epoch 36/150\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 0.1643 - acc: 0.9382\n",
      "Epoch 37/150\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 0.1648 - acc: 0.9380\n",
      "Epoch 38/150\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 0.1585 - acc: 0.9407\n",
      "Epoch 39/150\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.1548 - acc: 0.9436\n",
      "Epoch 40/150\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 0.1531 - acc: 0.9443\n",
      "Epoch 41/150\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.1444 - acc: 0.9481\n",
      "Epoch 42/150\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.1452 - acc: 0.9456\n",
      "Epoch 43/150\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 0.1425 - acc: 0.9480\n",
      "Epoch 44/150\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 0.1360 - acc: 0.9499\n",
      "Epoch 45/150\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 0.1344 - acc: 0.9515\n",
      "Epoch 46/150\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 0.1354 - acc: 0.9491\n",
      "Epoch 47/150\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.1249 - acc: 0.9554\n",
      "Epoch 48/150\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 0.1267 - acc: 0.9534\n",
      "Epoch 49/150\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 0.1226 - acc: 0.9562\n",
      "Epoch 50/150\n",
      "8000/8000 [==============================] - 0s 47us/step - loss: 0.1245 - acc: 0.9536\n",
      "Epoch 51/150\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.1230 - acc: 0.9570\n",
      "Epoch 52/150\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 0.1121 - acc: 0.9584\n",
      "Epoch 53/150\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 0.1199 - acc: 0.9580\n",
      "Epoch 54/150\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 0.1102 - acc: 0.9584\n",
      "Epoch 55/150\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 0.1101 - acc: 0.9604\n",
      "Epoch 56/150\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.1095 - acc: 0.9599\n",
      "Epoch 57/150\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 0.1151 - acc: 0.9574\n",
      "Epoch 58/150\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 0.1067 - acc: 0.9615\n",
      "Epoch 59/150\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.1074 - acc: 0.9605\n",
      "Epoch 60/150\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.1034 - acc: 0.9629\n",
      "Epoch 61/150\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 0.1009 - acc: 0.9611\n",
      "Epoch 62/150\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.0960 - acc: 0.9675\n",
      "Epoch 63/150\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 0.1018 - acc: 0.9626\n",
      "Epoch 64/150\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.0958 - acc: 0.9633\n",
      "Epoch 65/150\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.0957 - acc: 0.9674\n",
      "Epoch 66/150\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.0931 - acc: 0.9651\n",
      "Epoch 67/150\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.0900 - acc: 0.9695\n",
      "Epoch 68/150\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 0.0863 - acc: 0.9693\n",
      "Epoch 69/150\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 0.0892 - acc: 0.9690\n",
      "Epoch 70/150\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 0.0811 - acc: 0.9730\n",
      "Epoch 71/150\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 0.0822 - acc: 0.9731\n",
      "Epoch 72/150\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.0814 - acc: 0.9700\n",
      "Epoch 73/150\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.0804 - acc: 0.9724\n",
      "Epoch 74/150\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.0767 - acc: 0.9743\n",
      "Epoch 75/150\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.0809 - acc: 0.9713\n",
      "Epoch 76/150\n",
      "8000/8000 [==============================] - 0s 47us/step - loss: 0.0756 - acc: 0.9748\n",
      "Epoch 77/150\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.0799 - acc: 0.9713\n",
      "Epoch 78/150\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.0737 - acc: 0.9735\n",
      "Epoch 79/150\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.0719 - acc: 0.9751\n",
      "Epoch 80/150\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.0742 - acc: 0.9755\n",
      "Epoch 81/150\n",
      "8000/8000 [==============================] - 0s 47us/step - loss: 0.0723 - acc: 0.9755\n",
      "Epoch 82/150\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 0.0719 - acc: 0.9743\n",
      "Epoch 83/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 49us/step - loss: 0.0717 - acc: 0.9748\n",
      "Epoch 84/150\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.0645 - acc: 0.9769\n",
      "Epoch 85/150\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.0682 - acc: 0.9760: 0s - loss: 0.0687 - acc: 0.975\n",
      "Epoch 86/150\n",
      "8000/8000 [==============================] - 0s 47us/step - loss: 0.0678 - acc: 0.9764\n",
      "Epoch 87/150\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.0634 - acc: 0.9765\n",
      "Epoch 88/150\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.0642 - acc: 0.9759\n",
      "Epoch 89/150\n",
      "8000/8000 [==============================] - 0s 47us/step - loss: 0.0660 - acc: 0.9755\n",
      "Epoch 90/150\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.0636 - acc: 0.9795\n",
      "Epoch 91/150\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.0614 - acc: 0.9796\n",
      "Epoch 92/150\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.0651 - acc: 0.9774\n",
      "Epoch 93/150\n",
      "8000/8000 [==============================] - 0s 47us/step - loss: 0.0598 - acc: 0.9803\n",
      "Epoch 94/150\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.0554 - acc: 0.9798\n",
      "Epoch 95/150\n",
      "8000/8000 [==============================] - 0s 47us/step - loss: 0.0642 - acc: 0.9778\n",
      "Epoch 96/150\n",
      "8000/8000 [==============================] - 0s 47us/step - loss: 0.0596 - acc: 0.9789\n",
      "Epoch 97/150\n",
      "8000/8000 [==============================] - 0s 47us/step - loss: 0.0598 - acc: 0.9809\n",
      "Epoch 98/150\n",
      "8000/8000 [==============================] - 0s 47us/step - loss: 0.0534 - acc: 0.9809\n",
      "Epoch 99/150\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.0573 - acc: 0.9801\n",
      "Epoch 100/150\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.0561 - acc: 0.9794\n",
      "Epoch 101/150\n",
      "8000/8000 [==============================] - 0s 47us/step - loss: 0.0544 - acc: 0.9809\n",
      "Epoch 102/150\n",
      "8000/8000 [==============================] - 0s 47us/step - loss: 0.0561 - acc: 0.9819\n",
      "Epoch 103/150\n",
      "8000/8000 [==============================] - 0s 47us/step - loss: 0.0547 - acc: 0.9811\n",
      "Epoch 104/150\n",
      "8000/8000 [==============================] - 0s 47us/step - loss: 0.0554 - acc: 0.9831\n",
      "Epoch 105/150\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.0530 - acc: 0.9818\n",
      "Epoch 106/150\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.0524 - acc: 0.9810\n",
      "Epoch 107/150\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.0521 - acc: 0.9825\n",
      "Epoch 108/150\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.0519 - acc: 0.9818\n",
      "Epoch 109/150\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 0.0530 - acc: 0.9811\n",
      "Epoch 110/150\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 0.0508 - acc: 0.9833\n",
      "Epoch 111/150\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.0537 - acc: 0.9818\n",
      "Epoch 112/150\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 0.0465 - acc: 0.9841\n",
      "Epoch 113/150\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 0.0507 - acc: 0.9838\n",
      "Epoch 114/150\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.0524 - acc: 0.9821\n",
      "Epoch 115/150\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 0.0478 - acc: 0.9836\n",
      "Epoch 116/150\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 0.0477 - acc: 0.9818\n",
      "Epoch 117/150\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.0450 - acc: 0.9843\n",
      "Epoch 118/150\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.0424 - acc: 0.9864\n",
      "Epoch 119/150\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 0.0450 - acc: 0.9851\n",
      "Epoch 120/150\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 0.0461 - acc: 0.9836\n",
      "Epoch 121/150\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.0481 - acc: 0.9836\n",
      "Epoch 122/150\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.0477 - acc: 0.9830\n",
      "Epoch 123/150\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.0404 - acc: 0.9860\n",
      "Epoch 124/150\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.0429 - acc: 0.9848\n",
      "Epoch 125/150\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 0.0423 - acc: 0.9868\n",
      "Epoch 126/150\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.0430 - acc: 0.9848\n",
      "Epoch 127/150\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 0.0399 - acc: 0.9879\n",
      "Epoch 128/150\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 0.0389 - acc: 0.9860\n",
      "Epoch 129/150\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 0.0437 - acc: 0.9849\n",
      "Epoch 130/150\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.0444 - acc: 0.9841\n",
      "Epoch 131/150\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.0388 - acc: 0.9881\n",
      "Epoch 132/150\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 0.0454 - acc: 0.9848\n",
      "Epoch 133/150\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 0.0362 - acc: 0.9874\n",
      "Epoch 134/150\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 0.0413 - acc: 0.9854\n",
      "Epoch 135/150\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 0.0409 - acc: 0.9845\n",
      "Epoch 136/150\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 0.0362 - acc: 0.9873\n",
      "Epoch 137/150\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 0.0391 - acc: 0.9869\n",
      "Epoch 138/150\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 0.0357 - acc: 0.9886\n",
      "Epoch 139/150\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 0.0396 - acc: 0.9845\n",
      "Epoch 140/150\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 0.0393 - acc: 0.9865\n",
      "Epoch 141/150\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 0.0381 - acc: 0.9863\n",
      "Epoch 142/150\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 0.0368 - acc: 0.9866\n",
      "Epoch 143/150\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.0393 - acc: 0.9864\n",
      "Epoch 144/150\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 0.0387 - acc: 0.9868\n",
      "Epoch 145/150\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 0.0348 - acc: 0.9873\n",
      "Epoch 146/150\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 0.0362 - acc: 0.9868\n",
      "Epoch 147/150\n",
      "8000/8000 [==============================] - 0s 47us/step - loss: 0.0365 - acc: 0.9880\n",
      "Epoch 148/150\n",
      "8000/8000 [==============================] - 0s 48us/step - loss: 0.0352 - acc: 0.9873\n",
      "Epoch 149/150\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 0.0367 - acc: 0.9870\n",
      "Epoch 150/150\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 0.0302 - acc: 0.9889\n",
      "2000/2000 [==============================] - 0s 129us/step\n",
      "acc: 84.00%\n"
     ]
    }
   ],
   "source": [
    "# Training Settings\n",
    "#model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy']) #acc: 82.75%\n",
    "#model.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy']) #acc: 83.55%\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adadelta', metrics=['accuracy']) #acc: 83.85%\n",
    "#Model Training\n",
    "model.fit(x_train, y_train, epochs=150, batch_size=80)\n",
    "# Model Evaluation\n",
    "scores = model.evaluate(x_test, y_test)\n",
    "print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
